# Cluster_PySpark_Kafka
PySpark e Apache Kafka Para Processamento de Dados em Batch e Streaming. Preparação do Ambiente de Trabalho com Python e PySpark. Configuração do Cluster PySpark utilizando docker desktop virtualizando um SO Linux Ubuntu com o WSL2.
